import os
from flask import Flask,redirect,render_template,request
import urllib
import datetime
import json
import ibm_db
import geocoder
import geopy.distance
from config import *
import time
from cachetools import cached, Cache
import pandas as pd

app = Flask(__name__)
cache = Cache(maxsize=1000000)

@cached(cache)
def load_csv(fname, ftype):
    df = pd.read_csv('./static/{}.{}'.format(fname, ftype))
    return df



@cached(cache)
def save_file(fname):
    f = open('./static/{}.txt'.format(fname), 'w')
    return f



cache_csv = load_csv('all_month', 'csv')

if 'VCAP_SERVICES' in os.environ:
    db2info = json.loads(os.environ['VCAP_SERVICES'])['dashDB For Transactions'][0]
    db2cred = db2info["credentials"]
    appenv = json.loads(os.environ['VCAP_APPLICATION'])
else:
    raise ValueError('Expected cloud environment')



# main page to dump some environment information
@app.route('/')
def index():
   return render_template('index.html', app=appenv)



# for testing purposes - use name in URI
@app.route('/hello/<name>')
def hello(name=None):
    return render_template('hello.html', name=name)



@app.route('/cal_create')
def cal_create():
    mode = request.args.get('mode1') if request.args.get('mode1') else request.args.get('mode2')
    mode = mode.split(' ')[0]
    start = time.time()
    tbl_nm = request.args.get('name')
    
    if mode=='RDB':    
        # connect to DB2
        db2conn = ibm_db.connect(db2cred['ssldsn'], "","")
        if db2conn:
            sql = """CREATE TABLE {}(
                     store_id INT GENERATED BY DEFAULT AS IDENTITY NOT NULL,
                     store_name VARCHAR(150) NOT NULL,
                     address_line_1 VARCHAR(255) NOT NULL,
                     address_line_2 VARCHAR(100),
                     city_id INT NOT NULL,
                     state_id INT NOT NULL,
                     zip_code VARCHAR(6),
                     PRIMARY KEY (store_id));
                  """.format(tbl_nm)
            ibm_db.exec_immediate(db2conn, sql)
            ibm_db.close(db2conn)
    elif mode=='Memcache':
        save_file(tbl_nm)
        
    end = time.time()
    elapse = end - start
        
    return render_template('index.html', app=appenv, create_elp=elapse)



@app.route('/insert')
def insert():
    mode = request.args.get('mode1') if request.args.get('mode1') else request.args.get('mode2')
    mode = mode.split(' ')[-1]
    
    etime = request.args.get('time') if request.args.get('time') else -1
    lat = request.args.get('lat') if request.args.get('lat') else -1 
    lon = request.args.get('lon') if request.args.get('lon') else -1
    dep = request.args.get('dep') if request.args.get('dep') else -1
    mag = request.args.get('mag') if request.args.get('mag') else -1
    magtype = request.args.get('magtype') if request.args.get('magtype') else -1
    nst = request.args.get('nst') if request.args.get('nst') else -1
    gap = request.args.get('gap') if request.args.get('gap') else -1
    dmin = request.args.get('dmin') if request.args.get('dmin') else -1
    rms = request.args.get('rms') if request.args.get('rms') else -1
    net = request.args.get('net') if request.args.get('net') else -1
    eid = request.args.get('id') if request.args.get('id') else -1
    updated = request.args.get('updated') if request.args.get('updated') else -1
    place = request.args.get('place') if request.args.get('place') else -1
    etype = request.args.get('type') if request.args.get('type') else -1
    he = request.args.get('he') if request.args.get('he') else -1
    de = request.args.get('de') if request.args.get('de') else -1
    me = request.args.get('me') if request.args.get('me') else -1
    mn = request.args.get('mn') if request.args.get('mn') else -1
    status = request.args.get('status') if request.args.get('status') else -1
    locsource = request.args.get('locsource') if request.args.get('locsource') else -1
    magsource = request.args.get('magsource') if request.args.get('magsource') else -1
    start = time.time()
    # connect to DB2
    if mode=='RDB':
        db2conn = ibm_db.connect(db2cred['ssldsn'], "","")
        if db2conn:
            sql = """INSERT INTO EARTHQUAKE \
                    (TIME, LATITUDE, LONGTITUDE, DEPTH, MAG, \
                    MAGTYPE, NST, GAP, DMIN, RMS, NET, ID, UPDATED, \
                    PLACE, TYPE, HOTIZONTALERROR, DEPTHERROR, \
                    MAGERROR, MAGNST, STATUS, LOCATIONSOURCE, MAGSOURCE) \
                    VALUES ({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {});""".format(etime, lat, lon, dep, mag, magtype, nst, gap, dmin, rms, net, eid, updated, place, etype, he, de, me, mn, status, locsource, magsource)
            ibm_db.exec_immediate(db2conn, sql)
    elif mode=='Memcache':
        tmp = pd.DataFrame([[etime, float(lat), float(lon), float(dep), float(mag), magtype, float(nst), float(gap), float(dmin), float(rms), net, eid, updated, place, etype, float(he), float(de), float(me), float(mn), status, locsource, magsource]])
        tmp.columns = ['TIME', 'LATITUDE', 'LONGTITUDE', 'DEPTH', 'MAG', 'MAGTYPE', 'NST', 'GAP', 'DMIN', 'RMS', 'NET', 'ID', 'UPDATED', 'PLACE', 'TYPE', 'HOTIZONTALERROR', 'DEPTHERROR', 'MAGERROR', 'MAGNST', 'STATUS', 'LOCATIONSOURCE', 'MAGSOURCE']
        global cache_csv
        cache_csv = cache_csv.append(tmp, ignore_index=True)

    end = time.time()
    elapse = end - start    
    return render_template('index.html', app=appenv, insert_elp=elapse)



@app.route('/delete')
def delete():
    mode = request.args.get('dmode1') if request.args.get('dmode1') else request.args.get('dmode2')
    mode = mode.split(' ')[-1]
    start = time.time()
    
    etime = request.args.get('time') if request.args.get('time') else 'None'
    lat = request.args.get('lat') if request.args.get('lat') else -1 
    lon = request.args.get('lon') if request.args.get('lon') else -1
    dep = request.args.get('dep') if request.args.get('dep') else -1
    mag = request.args.get('mag') if request.args.get('mag') else -1
    magtype = request.args.get('magtype') if request.args.get('magtype') else 'None'
    nst = request.args.get('nst') if request.args.get('nst') else -1
    gap = request.args.get('gap') if request.args.get('gap') else -1
    dmin = request.args.get('dmin') if request.args.get('dmin') else -1
    rms = request.args.get('rms') if request.args.get('rms') else -1
    net = request.args.get('net') if request.args.get('net') else 'None'
    eid = request.args.get('id') if request.args.get('id') else 'None'
    updated = request.args.get('updated') if request.args.get('updated') else 'None'
    place = request.args.get('place') if request.args.get('place') else 'None'
    etype = request.args.get('type') if request.args.get('type') else 'None'
    he = request.args.get('he') if request.args.get('he') else -1
    de = request.args.get('de') if request.args.get('de') else -1
    me = request.args.get('me') if request.args.get('me') else -1
    mn = request.args.get('mn') if request.args.get('mn') else -1
    status = request.args.get('status') if request.args.get('status') else 'None'
    locsource = request.args.get('locsource') if request.args.get('locsource') else 'None'
    magsource = request.args.get('magsource') if request.args.get('magsource') else 'None'
    
    params = {"TIME": etime, 
              "Latitude": lat,
              "LONGTITUDE": lon,
              "DEPTH": dep, 
              "MAG": mag, 
              "MAGTYPE": magtype, 
              "NST": nst, 
              "GAP": gap, 
              "DMIN": dmin, 
              "RMS": rms, 
              "NET": net, 
              "ID": eid, 
              "UPDATED": updated, 
              "PLACE": place, 
              "TYPE": etype, 
              "HOTIZONTALERROR": he, 
              "DEPTHERROR": de, 
              "MAGERROR": me, 
              "MAGNST": mn, 
              "STATUS": status, 
              "LOCATIONSOURCE": locsource, 
              "MAGSOURCE": magsource,
              }

    params = [(k, v) for k, v in params.items() if v not in [-1, 'None']]
    sub_sql = ', '.join([p[0]+'='+str(p[1]) for p in params])
    if mode=='RDB':
        # connect to DB2
        db2conn = ibm_db.connect(db2cred['ssldsn'], "","")
        if db2conn:
            sql = """DELETE FROM EARTHQUAKE WHERE {}""".format(sub_sql)
            ibm_db.exec_immediate(db2conn, sql)
    elif mode=='Memcache':
        for p in params:
            global cache_csv
            cache_csv = cache_csv[cache_csv[p[0]]!=p[1]]
        
    end = time.time()
    elapse = end - start    
    return render_template('index.html', app=appenv, delete_elp=elapse)



@app.route('/search_largest_n', methods=['GET'])
def largest_n():
    mode = request.args.get('mode1') if request.args.get('mode1') else request.args.get('mode2')
    mode = mode.split(' ')[1]
    start = time.time()
    number = request.args.get('number') if request.args.get('number') else 5
    if mode=='RDB':
        # connect to DB2
        db2conn = ibm_db.connect(db2cred['ssldsn'], "","")
        if db2conn:
            sql = "SELECT * FROM EARTHQUAKE ORDER BY MAG DESC FETCH FIRST ? ROWS ONLY;"
            stmt = ibm_db.prepare(db2conn, sql)
            ibm_db.bind_param(stmt, 1, number)
            ibm_db.execute(stmt)
            
            rows=[]
            result = ibm_db.fetch_assoc(stmt)
            while result != False:
                rows.append(result.copy())
                result = ibm_db.fetch_assoc(stmt)
            
            ibm_db.close(db2conn)
    elif mode=='Memcache':
        tmp = cache_csv.sort_values(by='MAG', ascending=False)
        rows = tmp[:int(number)].reset_index().to_dict(orient='records')
        
    end = time.time()
    elapse = end - start
    return render_template('large_n.html', ci=rows, elapse=elapse)



@app.route('/search_around_place', methods=['GET'])
def search_around_place():
    mode = request.args.get('mode1') if request.args.get('mode1') else request.args.get('mode2')
    mode = mode.split(' ')[1]
    
    start = time.time()
    distance = request.args.get('distance', 500)
    city = request.args.get('city', 'arlington')
    
    usr_g_json = geocoder.osm(city).json
    trgt_coords = (usr_g_json['lat'], usr_g_json['lng'])

    if mode=='RDB':
        db2conn = ibm_db.connect(db2cred['ssldsn'], "","")
        if db2conn:
            sql = "SELECT * FROM EARTHQUAKE"
            stmt = ibm_db.exec_immediate(db2conn, sql)
            rows=[]
            result = ibm_db.fetch_assoc(stmt)
            while result != False:
                try:
                    curr_coords = (result['LATITUDE'], result['LONGTITUDE'])
                    if geopy.distance.vincenty(curr_coords, trgt_coords).km<distance:
                        rows.append(result.copy())
                    result = ibm_db.fetch_assoc(stmt)
                except:
                    result = ibm_db.fetch_assoc(stmt)
            ibm_db.close(db2conn)
    elif mode=='Memcache':
        rows = []
        for _, row in cache_csv.iterrows():
            curr_coords = (row['LATITUDE'], row['LONGTITUDE'])
            if geopy.distance.vincenty(curr_coords, trgt_coords).km<distance:
                rows.append(row)
    end = time.time()
    elapse = end - start
    return render_template('search_around_place.html', ci=rows, elapse=elapse)


port = os.getenv('PORT', '5000')
if __name__ == "__main__":
	app.run(host='0.0.0.0', port=int(port))
